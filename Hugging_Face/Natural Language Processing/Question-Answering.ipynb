{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c42cf15",
   "metadata": {},
   "source": [
    "# Question Answering\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "Question Answering models can retrieve the answer to a question from a given text, which is useful for searching for an answer in a document. \n",
    "\n",
    "Some question answering models can generate answers without context!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51956181",
   "metadata": {},
   "source": [
    "### **Use Cases**\n",
    "\n",
    "---\n",
    "\n",
    "#### **Frequently Asked Questions**\n",
    "\n",
    "* One can use Question Answering (QA) models to automate the response to frequently asked questions by using a knowledge base (documents) as context. \n",
    "\n",
    "* Answers to customer questions can be drawn from those documents.\n",
    "\n",
    "* âš¡âš¡ If youâ€™d like to save inference time, you can first use passage ranking models to see which document might contain the answer to the question and iterate over that document with the QA model instead.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e8c85a",
   "metadata": {},
   "source": [
    "### *Task Variants* \n",
    "\n",
    "--- \n",
    "\n",
    "There are different QA variants based on the inputs and outputs:\n",
    "\n",
    "**Extractive QA:** \n",
    "- The model extracts the answer from a context. \n",
    "- The context here could be a provided text, a table or even HTML! \n",
    "- This is usually solved with BERT-like models.\n",
    "\n",
    "**Open Generative QA:**\n",
    "- The model generates free text directly based on the context. \n",
    "\n",
    "**Closed Generative QA:**\n",
    "- In this case, no context is provided. \n",
    "- The answer is completely generated by a model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5745dd1e",
   "metadata": {},
   "source": [
    "* The schema above illustrates extractive, open book QA. \n",
    "\n",
    "* The model takes a context and the question and extracts the answer from the given context.\n",
    "\n",
    "* You can also differentiate QA models depending on whether they are open-domain or closed-domain. \n",
    "\n",
    "* **Open-domain models** are not restricted to a specific domain, while **closed-domain models** are restricted to a specific domain (e.g. legal, medical documents).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cba4385",
   "metadata": {},
   "source": [
    "### **Inference**\n",
    "\n",
    "---\n",
    "\n",
    "* You can infer with QA models with the ðŸ¤— Transformers library using the question-answering pipeline. \n",
    "* If no model checkpoint is given, the pipeline will be initialized with distilbert-base-cased-distilled-squad.\n",
    "* This pipeline takes a question and a context from which the answer will be extracted and returned."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b21ace",
   "metadata": {},
   "source": [
    "### **Metrics for Fill-Mask**\n",
    "\n",
    "---\n",
    "\n",
    "* **exact-match** : Exact Match is a metric based on the strict character match of the predicted answer and the right answer. For answers predicted correctly, the Exact Match will be 1. Even if only one character is different, Exact Match will be 0.\n",
    "\n",
    "* **f1** : The F1-Score metric is useful if we value both false positives and false negatives equally. The F1-Score is calculated on each word in the predicted sequence against the correct answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a29e6d6",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db703bfa",
   "metadata": {},
   "source": [
    "##### Importing Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3cd8a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fe7da9",
   "metadata": {},
   "source": [
    "##### Initializing Pipeline for Question-Anwering Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdf466bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77d0be496f194505bab737a9943aeede",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/473 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a646bcc52cb47aa80588398372596b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/261M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fd1fd9c012848faa51730ff1fbd9130",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f5a607f3dae4c8181ccaa2bed4dd9e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a875cb0b33ca47e08292841d68b75842",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/436k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "qa_model = pipeline(\"question-answering\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64293f7f",
   "metadata": {},
   "source": [
    "##### Specifying Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2d08f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"My name is Hanifa and I live in Karachi, Pakistan. I am a fresh graduate from NED University of Engineering and Technology.  I graduated last year.  I acquired a BE degree in Software Engineering. in 2022, I got job opportunity in isystematic, LLC\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ea7022",
   "metadata": {},
   "source": [
    "##### Sample run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2710b69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.9322136044502258,\n",
       " 'start': 32,\n",
       " 'end': 49,\n",
       " 'answer': 'Karachi, Pakistan'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"Where do I live?\"\n",
    "qa_model(question = question, context = context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ffebb133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.5403902530670166, 'start': 32, 'end': 39, 'answer': 'Karachi'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"What's my city?\"\n",
    "qa_model(question = question, context = context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3904d22e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.9795141816139221, 'start': 41, 'end': 49, 'answer': 'Pakistan'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"What's my country?\"\n",
    "qa_model(question = question, context = context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77431fd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.6208661794662476,\n",
       " 'start': 162,\n",
       " 'end': 195,\n",
       " 'answer': 'BE degree in Software Engineering'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"Whats my degree?\"\n",
    "qa_model(question = question, context = context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3f353c47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.9978432059288025, 'start': 11, 'end': 17, 'answer': 'Hanifa'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"What's my name?\"\n",
    "qa_model(question = question, context = context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "45df4612",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.27684080600738525,\n",
       " 'start': 175,\n",
       " 'end': 195,\n",
       " 'answer': 'Software Engineering'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"I opted which profession?\"\n",
    "qa_model(question = question, context = context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ddf4f3f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.9294475317001343, 'start': 137, 'end': 146, 'answer': 'last year'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"When do I graduated?\"\n",
    "qa_model(question = question, context = context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "82b56efb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.9766813516616821,\n",
       " 'start': 78,\n",
       " 'end': 122,\n",
       " 'answer': 'NED University of Engineering and Technology'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"From where I graduated?\"\n",
    "qa_model(question = question, context = context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bbdcc206",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.2462228387594223,\n",
       " 'start': 231,\n",
       " 'end': 242,\n",
       " 'answer': 'isystematic'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"Hanifa is employeed where?\"\n",
    "qa_model(question = question, context = context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "edba391e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.9911038875579834, 'start': 200, 'end': 204, 'answer': '2022'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"In which year, I got the job opportunity?\"\n",
    "qa_model(question = question, context = context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7471f1ef",
   "metadata": {},
   "source": [
    "### **Source:**\n",
    "\n",
    "* https://huggingface.co/tasks/question-answering"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
